{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG - Evaluation\n",
    "\n",
    "LangChain offers several built-in evaluators that you can use to test the efficacy of your RAG pipeline. Since you've created a RAG pipeline, the QA Evaluator is a good fit.\n",
    "Remember that LLMs are probablistic -- responses will not be the exact same for each invocation. Evaluation results will differ between invocations, and they may be imperfect. Using the metrics as part of a larger holistic testing strategy for your RAG application is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import urllib.request\n",
    "from dotenv import dotenv_values\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(prompt=\"Enter your Azure OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = getpass.getpass(prompt=\"Enter your Azure OpenAI Endpoint: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/twenty-thousand-leagues-under-the-sea.txt'\n",
    "loader = TextLoader(filename)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1076, which is longer than the specified 1000\n",
      "Created a chunk of size 1042, which is longer than the specified 1000\n",
      "Created a chunk of size 1378, which is longer than the specified 1000\n",
      "Created a chunk of size 1094, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1057, which is longer than the specified 1000\n",
      "Created a chunk of size 1240, which is longer than the specified 1000\n",
      "Created a chunk of size 1034, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 1048, which is longer than the specified 1000\n",
      "Created a chunk of size 1149, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1091, which is longer than the specified 1000\n",
      "Created a chunk of size 1016, which is longer than the specified 1000\n",
      "Created a chunk of size 1145, which is longer than the specified 1000\n",
      "Created a chunk of size 1343, which is longer than the specified 1000\n",
      "Created a chunk of size 1809, which is longer than the specified 1000\n",
      "Created a chunk of size 1630, which is longer than the specified 1000\n",
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1032, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1171, which is longer than the specified 1000\n",
      "Created a chunk of size 1114, which is longer than the specified 1000\n",
      "Created a chunk of size 1085, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1007, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1526, which is longer than the specified 1000\n",
      "Created a chunk of size 1036, which is longer than the specified 1000\n",
      "Created a chunk of size 1278, which is longer than the specified 1000\n",
      "Created a chunk of size 1115, which is longer than the specified 1000\n",
      "Created a chunk of size 1383, which is longer than the specified 1000\n",
      "Created a chunk of size 1016, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1860, which is longer than the specified 1000\n",
      "Created a chunk of size 2613, which is longer than the specified 1000\n",
      "Created a chunk of size 1973, which is longer than the specified 1000\n",
      "Created a chunk of size 1581, which is longer than the specified 1000\n",
      "Created a chunk of size 1993, which is longer than the specified 1000\n",
      "Created a chunk of size 3878, which is longer than the specified 1000\n",
      "Created a chunk of size 1521, which is longer than the specified 1000\n",
      "Created a chunk of size 1523, which is longer than the specified 1000\n",
      "Created a chunk of size 1467, which is longer than the specified 1000\n",
      "Created a chunk of size 2714, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 1477, which is longer than the specified 1000\n",
      "Created a chunk of size 2863, which is longer than the specified 1000\n",
      "Created a chunk of size 1508, which is longer than the specified 1000\n",
      "Created a chunk of size 1294, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 1355, which is longer than the specified 1000\n",
      "Created a chunk of size 2352, which is longer than the specified 1000\n",
      "Created a chunk of size 1700, which is longer than the specified 1000\n",
      "Created a chunk of size 1460, which is longer than the specified 1000\n",
      "Created a chunk of size 1902, which is longer than the specified 1000\n",
      "Created a chunk of size 2208, which is longer than the specified 1000\n",
      "Created a chunk of size 1482, which is longer than the specified 1000\n",
      "Created a chunk of size 3652, which is longer than the specified 1000\n",
      "Created a chunk of size 1998, which is longer than the specified 1000\n",
      "Created a chunk of size 1927, which is longer than the specified 1000\n",
      "Created a chunk of size 2859, which is longer than the specified 1000\n",
      "Created a chunk of size 1432, which is longer than the specified 1000\n",
      "Created a chunk of size 2550, which is longer than the specified 1000\n",
      "Created a chunk of size 1063, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1730, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1230, which is longer than the specified 1000\n",
      "Created a chunk of size 1328, which is longer than the specified 1000\n",
      "Created a chunk of size 4766, which is longer than the specified 1000\n",
      "Created a chunk of size 1488, which is longer than the specified 1000\n",
      "Created a chunk of size 1253, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n",
      "Created a chunk of size 1078, which is longer than the specified 1000\n",
      "Created a chunk of size 1712, which is longer than the specified 1000\n",
      "Created a chunk of size 1083, which is longer than the specified 1000\n",
      "Created a chunk of size 3322, which is longer than the specified 1000\n",
      "Created a chunk of size 1043, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1132, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure embeddings model and the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"text-embedding-ada-002\",\n",
    "    openai_api_version=\"2023-05-15\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The platform was only three feet out of water. The front and back of\\nthe _Nautilus_ was of that spindle-shape which caused it justly to be\\ncompared to a cigar. I noticed that its iron plates, slightly\\noverlaying each other, resembled the shell which clothes the bodies of\\nour large terrestrial reptiles. It explained to me how natural it was,\\nin spite of all glasses, that this boat should have been taken for a\\nmarine animal.\\n\\nToward the middle of the platform the long-boat, half buried in the\\nhull of the vessel, formed a slight excrescence. Fore and aft rose two\\ncages of medium height with inclined sides, and partly closed by thick\\nlenticular glasses; one destined for the steersman who directed the\\n_Nautilus_, the other containing a brilliant lantern to give light on\\nthe road.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the Nautilus?\"\n",
    "data = vector_db.similarity_search(query)\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The platform was only three feet out of water. The front and back of\\nthe _Nautilus_ was of that spindle-shape which caused it justly to be\\ncompared to a cigar. I noticed that its iron plates, slightly\\noverlaying each other, resembled the shell which clothes the bodies of\\nour large terrestrial reptiles. It explained to me how natural it was,\\nin spite of all glasses, that this boat should have been taken for a\\nmarine animal.\\n\\nToward the middle of the platform the long-boat, half buried in the\\nhull of the vessel, formed a slight excrescence. Fore and aft rose two\\ncages of medium height with inclined sides, and partly closed by thick\\nlenticular glasses; one destined for the steersman who directed the\\n_Nautilus_, the other containing a brilliant lantern to give light on\\nthe road.' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='During several hours the _Nautilus_ floated in these brilliant waves,\\nand our admiration increased as we watched the marine monsters\\ndisporting themselves like salamanders. I saw there in the midst of\\nthis fire that burns not the swift and elegant porpoise (the\\nindefatigable clown of the ocean), and some swordfish ten feet long,\\nthose prophetic heralds of the hurricane whose formidable sword would\\nnow and then strike the glass of the saloon. Then appeared the smaller\\nfish, the balista, the leaping mackerel, wolf-thorn-tails, and a\\nhundred others which striped the luminous atmosphere as they swam. This\\ndazzling spectacle was enchanting! Perhaps some atmospheric condition\\nincreased the intensity of this phenomenon. Perhaps some storm agitated\\nthe surface of the waves. But at this depth of some yards, the\\n_Nautilus_ was unmoved by its fury and reposed peacefully in still\\nwater.' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='But what has become of the _Nautilus?_ Did it resist the pressure of\\nthe maelstrom? Does Captain Nemo still live? And does he still follow\\nunder the ocean those frightful retaliations? Or, did he stop after the\\nlast hecatomb?\\n\\nWill the waves one day carry to him this manuscript containing the\\nhistory of his life? Shall I ever know the name of this man? Will the\\nmissing vessel tell us by its nationality that of Captain Nemo?' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum marginal relevance retrieval \n",
    "By default, the vector store retriever uses similarity search. If the underlying vector store supports maximum marginal relevance search, you can specify that as the search type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The platform was only three feet out of water. The front and back of\\nthe _Nautilus_ was of that spindle-shape which caused it justly to be\\ncompared to a cigar. I noticed that its iron plates, slightly\\noverlaying each other, resembled the shell which clothes the bodies of\\nour large terrestrial reptiles. It explained to me how natural it was,\\nin spite of all glasses, that this boat should have been taken for a\\nmarine animal.\\n\\nToward the middle of the platform the long-boat, half buried in the\\nhull of the vessel, formed a slight excrescence. Fore and aft rose two\\ncages of medium height with inclined sides, and partly closed by thick\\nlenticular glasses; one destined for the steersman who directed the\\n_Nautilus_, the other containing a brilliant lantern to give light on\\nthe road.' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='But what has become of the _Nautilus?_ Did it resist the pressure of\\nthe maelstrom? Does Captain Nemo still live? And does he still follow\\nunder the ocean those frightful retaliations? Or, did he stop after the\\nlast hecatomb?\\n\\nWill the waves one day carry to him this manuscript containing the\\nhistory of his life? Shall I ever know the name of this man? Will the\\nmissing vessel tell us by its nationality that of Captain Nemo?' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='“I have seen the _Nautilus_ manœuvre before the _Abraham Lincoln_, and\\nI have my own ideas as to its speed. But this is not enough. We must\\nsee where we go. We must be able to direct it to the right, to the\\nleft, above, below. How do you get to the great depths, where you find\\nan increasing resistance, which is rated by hundreds of atmospheres?\\nHow do you return to the surface of the ocean? And how do you maintain\\nyourselves in the requisite medium? Am I asking too much?”\\n\\n“Not at all, Professor,” replied the Captain, with some hesitation;\\n“since you may never leave this submarine boat. Come into the saloon,\\nit is our usual study, and there you will learn all you want to know\\nabout the _Nautilus_.”\\n\\n\\nCHAPTER XII\\nSOME FIGURES\\n\\n\\nA moment after we were seated on a divan in the saloon smoking. The\\nCaptain showed me a sketch that gave the plan, section, and elevation\\nof the _Nautilus_. Then he began his description in these words:—' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='From the 21st to the 23rd of January the _Nautilus_ went at the rate of\\ntwo hundred and fifty leagues in twenty-four hours, being five hundred\\nand forty miles, or twenty-two miles an hour. If we recognised so many\\ndifferent varieties of fish, it was because, attracted by the electric\\nlight, they tried to follow us; the greater part, however, were soon\\ndistanced by our speed, though some kept their place in the waters of\\nthe _Nautilus_ for a time. The morning of the 24th, in 12° 5′ S. lat.,\\nand 94° 33′ long., we observed Keeling Island, a coral formation,\\nplanted with magnificent cocos, and which had been visited by Mr.\\nDarwin and Captain Fitzroy. The _Nautilus_ skirted the shores of this\\ndesert island for a little distance. Its nets brought up numerous\\nspecimens of polypi and curious shells of mollusca. Some precious\\nproductions of the species of delphinulae enriched the treasures of\\nCaptain Nemo, to which I added an astraea punctifera, a kind of\\nparasite polypus often found fixed to a shell.' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity score threshold retrieval\n",
    "You can also set a retrieval method that sets a similarity score threshold and only returns documents with a score above that threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The platform was only three feet out of water. The front and back of\\nthe _Nautilus_ was of that spindle-shape which caused it justly to be\\ncompared to a cigar. I noticed that its iron plates, slightly\\noverlaying each other, resembled the shell which clothes the bodies of\\nour large terrestrial reptiles. It explained to me how natural it was,\\nin spite of all glasses, that this boat should have been taken for a\\nmarine animal.\\n\\nToward the middle of the platform the long-boat, half buried in the\\nhull of the vessel, formed a slight excrescence. Fore and aft rose two\\ncages of medium height with inclined sides, and partly closed by thick\\nlenticular glasses; one destined for the steersman who directed the\\n_Nautilus_, the other containing a brilliant lantern to give light on\\nthe road.' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='During several hours the _Nautilus_ floated in these brilliant waves,\\nand our admiration increased as we watched the marine monsters\\ndisporting themselves like salamanders. I saw there in the midst of\\nthis fire that burns not the swift and elegant porpoise (the\\nindefatigable clown of the ocean), and some swordfish ten feet long,\\nthose prophetic heralds of the hurricane whose formidable sword would\\nnow and then strike the glass of the saloon. Then appeared the smaller\\nfish, the balista, the leaping mackerel, wolf-thorn-tails, and a\\nhundred others which striped the luminous atmosphere as they swam. This\\ndazzling spectacle was enchanting! Perhaps some atmospheric condition\\nincreased the intensity of this phenomenon. Perhaps some storm agitated\\nthe surface of the waves. But at this depth of some yards, the\\n_Nautilus_ was unmoved by its fury and reposed peacefully in still\\nwater.' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='But what has become of the _Nautilus?_ Did it resist the pressure of\\nthe maelstrom? Does Captain Nemo still live? And does he still follow\\nunder the ocean those frightful retaliations? Or, did he stop after the\\nlast hecatomb?\\n\\nWill the waves one day carry to him this manuscript containing the\\nhistory of his life? Shall I ever know the name of this man? Will the\\nmissing vessel tell us by its nationality that of Captain Nemo?' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n",
      "page_content='The _Nautilus_ was piercing the water with its sharp spur, after having\\naccomplished nearly ten thousand leagues in three months and a half, a\\ndistance greater than the great circle of the earth. Where were we\\ngoing now, and what was reserved for the future? The _Nautilus_,\\nleaving the Straits of Gibraltar, had gone far out. It returned to the\\nsurface of the waves, and our daily walks on the platform were restored\\nto us.\\n\\nI mounted at once, accompanied by Ned Land and Conseil. At a distance\\nof about twelve miles, Cape St. Vincent was dimly to be seen, forming\\nthe south-western point of the Spanish peninsula. A strong southerly\\ngale was blowing. The sea was swollen and billowy; it made the\\n_Nautilus_ rock violently. It was almost impossible to keep one’s foot\\non the platform, which the heavy rolls of the sea beat over every\\ninstant. So we descended after inhaling some mouthfuls of fresh air.' metadata={'source': '../data/twenty-thousand-leagues-under-the-sea.txt'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Answer the question based only on the supplied context. If you don't know the answer, say you don't know the answer.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Your answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_deployment=\"gpt-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Nautilus is a vessel or boat that is able to travel under water.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\n",
    "    \"In the given context, what is the Nautilus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "langsmith_api_key = \"LANGCHAIN_API_KEY\"\n",
    "if langsmith_api_key not in os.environ:\n",
    "    os.environ[langsmith_api_key] = getpass.getpass(f\"Enter {langsmith_api_key}: \")\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = input(\n",
    "    \"Project: \"\n",
    ")  # if not specified, defaults to \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"What is the name of Captain Nemo's submarine?\",\n",
    "    \"What passengers are there on Captain Nemo's submarine?\",\n",
    "    \"How can Professor Aronnax, Ned Land and Conseil escape?\",\n",
    "    \"What do the passengers eat for dinner?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"The name of Captain Nemo's submarine is Nautilus. It's featured in Jules Verne's novels Twenty Thousand Leagues Under the Sea and The Mysterious Island\", \n",
    "    \"The passengers aboard the Nautilus includes Professor Pierre Aronnax, a french marine biologist and the story's narrator, Conseil the loyal servant and Ned Land, a canadian harpooner.\", \n",
    "    \"They sneak onto a separate boat and make their escape from the submarine\",\n",
    "    \"The passengers enjoy a variety of exotic seafood dishes like sea cucumber, seaweed, and other undersea plants and creatures, prepared in a sophisticated manner\",\n",
    "]\n",
    "\n",
    "#examples = zip(eval_questions, eval_answers)\n",
    "examples = [{\"query\": q, \"ground_truths\": [eval_answers[i]]} \n",
    "           for i, q in enumerate(eval_questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': \"What is the name of Captain Nemo's submarine?\",\n",
       "  'ground_truths': [\"The name of Captain Nemo's submarine is Nautilus. It's featured in Jules Verne's novels Twenty Thousand Leagues Under the Sea and The Mysterious Island\"]},\n",
       " {'query': \"What passengers are there on Captain Nemo's submarine?\",\n",
       "  'ground_truths': [\"The passengers aboard the Nautilus includes Professor Pierre Aronnax, a french marine biologist and the story's narrator, Conseil the loyal servant and Ned Land, a canadian harpooner.\"]},\n",
       " {'query': 'How can Professor Aronnax, Ned Land and Conseil escape?',\n",
       "  'ground_truths': ['They sneak onto a separate boat and make their escape from the submarine']},\n",
       " {'query': 'What do the passengers eat for dinner?',\n",
       "  'ground_truths': ['The passengers enjoy a variety of exotic seafood dishes like sea cucumber, seaweed, and other undersea plants and creatures, prepared in a sophisticated manner']}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vector_db.as_retriever(),\n",
    "        return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The passengers aboard the Nautilus includes Professor Pierre Aronnax, a french marine biologist and the story's narrator, Conseil the loyal servant and Ned Land, a canadian harpooner.\"]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[1][\"ground_truths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`run` not supported when there is not exactly one output key. Got ['result', 'source_documents'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mqa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mground_truths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/chains/base.py:540\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convenience method for executing chain.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03mThe main difference between this method and `Chain.__call__` is that this\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;124;03m        # -> \"The temperature in Boise is...\"\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# Run at start to make sure this is possible/defined\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m _output_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_output_key\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/chains/base.py:488\u001b[0m, in \u001b[0;36mChain._run_output_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_output_key\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` not supported when there is not exactly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone output key. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m         )\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: `run` not supported when there is not exactly one output key. Got ['result', 'source_documents']."
     ]
    }
   ],
   "source": [
    "qa.run(examples[1][\"ground_truths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing dataset:  test_eval_dataset\n"
     ]
    }
   ],
   "source": [
    "# Create your dataset in LangSmith\n",
    "from langsmith import Client\n",
    "from langsmith.utils import LangSmithError\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"test_eval_dataset\"\n",
    "\n",
    "try:\n",
    "    # Check if dataset exists\n",
    "    dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "    print(\"using existing dataset: \", dataset.name)\n",
    "except LangSmithError:\n",
    "    # If not, create a new one with the eval questions\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"sample evaluation dataset\",\n",
    "    )\n",
    "    for question, answer in examples:\n",
    "        client.create_example(\n",
    "            inputs={\"input\": question},\n",
    "            outputs={\"answer\": answer},\n",
    "            dataset_id=dataset.id,\n",
    "        )\n",
    "\n",
    "    print(\"Created a new dataset: \", dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Since chains and agents can be stateful (they can have memory),\n",
    "# create a constructor to pass in to the run_on_dataset method.\n",
    "# This is so any state in the chain is not reused when evaluating individual examples.\n",
    "def create_qa_chain(llm, vector_store, return_context=True):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        return_source_documents=return_context,\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'cooked-judge-39' at:\n",
      "https://smith.langchain.com/o/93114361-1b4f-5f52-9a6b-e22e0e8fa9ec/datasets/f5b150f6-a2aa-4fd8-aab9-343a08ae245a/compare?selectedSessions=68b143ab-ec88-454e-8998-d6c907deffd1\n",
      "\n",
      "View all tests for Dataset test_eval_dataset at:\n",
      "https://smith.langchain.com/o/93114361-1b4f-5f52-9a6b-e22e0e8fa9ec/datasets/f5b150f6-a2aa-4fd8-aab9-343a08ae245a\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Evaluation with the <class 'langchain.evaluation.qa.eval_chain.QAEvalChain'> requires a language model to function. Failed to create the default 'gpt-4' model. Please manually provide an evaluation LLM or check your openai credentials.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/evaluation/loading.py:134\u001b[0m, in \u001b[0;36mload_evaluator\u001b[0;34m(evaluator, llm, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m evaluation_config \u001b[38;5;241m=\u001b[39m RunEvalConfig(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# LangChain offers several QA Evaluator types\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     evaluators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     prediction_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m client \u001b[38;5;241m=\u001b[39m Client()\n\u001b[0;32m---> 16\u001b[0m \u001b[43mrun_on_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_or_chain_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_qa_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_db\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/smith/evaluation/runner_utils.py:1297\u001b[0m, in \u001b[0;36mrun_on_dataset\u001b[0;34m(client, dataset_name, llm_or_chain_factory, evaluation, concurrency_level, project_name, project_metadata, verbose, tags, revision_id, **kwargs)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     warn_deprecated(\n\u001b[1;32m   1290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.305\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1291\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following arguments are deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.305\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1295\u001b[0m     )\n\u001b[1;32m   1296\u001b[0m client \u001b[38;5;241m=\u001b[39m client \u001b[38;5;129;01mor\u001b[39;00m Client()\n\u001b[0;32m-> 1297\u001b[0m container \u001b[38;5;241m=\u001b[39m \u001b[43m_DatasetRunContainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_or_chain_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_mapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcurrency_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concurrency_level \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1310\u001b[0m     batch_results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1311\u001b[0m         _run_llm_or_chain(\n\u001b[1;32m   1312\u001b[0m             example,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m example, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(container\u001b[38;5;241m.\u001b[39mexamples, container\u001b[38;5;241m.\u001b[39mconfigs)\n\u001b[1;32m   1318\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/smith/evaluation/runner_utils.py:1137\u001b[0m, in \u001b[0;36m_DatasetRunContainer.prepare\u001b[0;34m(cls, client, dataset_name, llm_or_chain_factory, project_name, evaluation, tags, input_mapper, concurrency_level, project_metadata, revision_id)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     tags\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1136\u001b[0m wrapped_model \u001b[38;5;241m=\u001b[39m _wrap_in_chain_factory(llm_or_chain_factory)\n\u001b[0;32m-> 1137\u001b[0m run_evaluators \u001b[38;5;241m=\u001b[39m \u001b[43m_setup_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m _validate_example_inputs(examples[\u001b[38;5;241m0\u001b[39m], wrapped_model, input_mapper)\n\u001b[1;32m   1141\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m progress\u001b[38;5;241m.\u001b[39mProgressBarCallback(\u001b[38;5;28mlen\u001b[39m(examples))\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/smith/evaluation/runner_utils.py:436\u001b[0m, in \u001b[0;36m_setup_evaluation\u001b[0;34m(llm_or_chain_factory, examples, evaluation, data_type)\u001b[0m\n\u001b[1;32m    434\u001b[0m         run_inputs \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minput_keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chain, Chain) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    435\u001b[0m         run_outputs \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39moutput_keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chain, Chain) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     run_evaluators \u001b[38;5;241m=\u001b[39m \u001b[43m_load_run_evaluators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# TODO: Create a default helpfulness evaluator\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     run_evaluators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/smith/evaluation/runner_utils.py:615\u001b[0m, in \u001b[0;36m_load_run_evaluators\u001b[0;34m(config, run_type, data_type, example_outputs, run_inputs, run_outputs)\u001b[0m\n\u001b[1;32m    611\u001b[0m     input_key, prediction_key, reference_key \u001b[38;5;241m=\u001b[39m _get_keys(\n\u001b[1;32m    612\u001b[0m         config, run_inputs, run_outputs, example_outputs\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eval_config \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mevaluators:\n\u001b[0;32m--> 615\u001b[0m     run_evaluator \u001b[38;5;241m=\u001b[39m \u001b[43m_construct_run_evaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m     run_evaluators\u001b[38;5;241m.\u001b[39mappend(run_evaluator)\n\u001b[1;32m    626\u001b[0m custom_evaluators \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mcustom_evaluators \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/smith/evaluation/runner_utils.py:528\u001b[0m, in \u001b[0;36m_construct_run_evaluator\u001b[0;34m(eval_config, eval_llm, run_type, data_type, example_outputs, reference_key, input_key, prediction_key)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_config, EvaluatorType):\n\u001b[1;32m    527\u001b[0m         eval_config \u001b[38;5;241m=\u001b[39m EvaluatorType(eval_config)\n\u001b[0;32m--> 528\u001b[0m     evaluator_ \u001b[38;5;241m=\u001b[39m \u001b[43mload_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_llm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m     eval_type_tag \u001b[38;5;241m=\u001b[39m eval_config\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Quellcodes/conversational-apps-with-langchain/.venv/lib/python3.11/site-packages/langchain/evaluation/loading.py:138\u001b[0m, in \u001b[0;36mload_evaluator\u001b[0;34m(evaluator, llm, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m ChatOpenAI(\n\u001b[1;32m    135\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m42\u001b[39m}, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation with the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator_cls\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage model to function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Failed to create the default \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please manually provide an evaluation LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or check your openai credentials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluator_cls\u001b[38;5;241m.\u001b[39mfrom_llm(llm\u001b[38;5;241m=\u001b[39mllm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Evaluation with the <class 'langchain.evaluation.qa.eval_chain.QAEvalChain'> requires a language model to function. Failed to create the default 'gpt-4' model. Please manually provide an evaluation LLM or check your openai credentials."
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from langchain.evaluation import EvaluatorType\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # LangChain offers several QA Evaluator types\n",
    "    evaluators=[\n",
    "        \"qa\", # grades a response as correct or incorrect based on reference answer\n",
    "        \"context_qa\", # uses reference context to to determine correctness \n",
    "        # \"cot_qa\", # similar to context_qa, but uses chain-of-thought\n",
    "    ],\n",
    "    prediction_key=\"result\",\n",
    ")\n",
    "\n",
    "client = Client()\n",
    "run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=create_qa_chain(llm=llm, vector_store=vector_db),\n",
    "    client=client,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
