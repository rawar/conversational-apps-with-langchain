{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG - Retrieval-Augmented Generation\n",
    "\n",
    "RAG extends the already powerful capabilities of LLMs to specific domains or an organization's internal knowledge base, all without the need to retrain the model. It is a cost-effective approach to improving LLM output so it remains relevant, accurate, and useful in various contexts.\n",
    "\n",
    "## How RAG works\n",
    "\n",
    "* Create external data\n",
    "* Retrieve relevant information\n",
    "* Augment the LLM prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from langchain_community.document_loaders import TextLoader, WebBaseLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain_community.vectorstores import SQLiteVSS\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from IPython.display import display, Markdown, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure embeddings model and the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"gemma:7b\"\n",
    "EMBEDDINGS_MODEL = \"nomic-embed-text:latest\"\n",
    "llm = ChatOllama(base_url=HOST, model=LLM_MODEL, temperature=0)\n",
    "embeddings_model = OllamaEmbeddings(base_url=HOST, model=EMBEDDINGS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the book 20.000 Leagues under the see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/twenty-thousand-leagues-under-the-sea.txt',\n",
       " <http.client.HTTPMessage at 0x12b24af90>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.gutenberg.org/cache/epub/164/pg164.txt'\n",
    "filename = '../data/twenty-thousand-leagues-under-the-sea.txt'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(filename)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1076, which is longer than the specified 1000\n",
      "Created a chunk of size 1042, which is longer than the specified 1000\n",
      "Created a chunk of size 1378, which is longer than the specified 1000\n",
      "Created a chunk of size 1094, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1057, which is longer than the specified 1000\n",
      "Created a chunk of size 1240, which is longer than the specified 1000\n",
      "Created a chunk of size 1034, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 1048, which is longer than the specified 1000\n",
      "Created a chunk of size 1149, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1091, which is longer than the specified 1000\n",
      "Created a chunk of size 1016, which is longer than the specified 1000\n",
      "Created a chunk of size 1145, which is longer than the specified 1000\n",
      "Created a chunk of size 1343, which is longer than the specified 1000\n",
      "Created a chunk of size 1809, which is longer than the specified 1000\n",
      "Created a chunk of size 1630, which is longer than the specified 1000\n",
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1032, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1171, which is longer than the specified 1000\n",
      "Created a chunk of size 1114, which is longer than the specified 1000\n",
      "Created a chunk of size 1085, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1007, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1526, which is longer than the specified 1000\n",
      "Created a chunk of size 1036, which is longer than the specified 1000\n",
      "Created a chunk of size 1278, which is longer than the specified 1000\n",
      "Created a chunk of size 1115, which is longer than the specified 1000\n",
      "Created a chunk of size 1383, which is longer than the specified 1000\n",
      "Created a chunk of size 1016, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1860, which is longer than the specified 1000\n",
      "Created a chunk of size 2613, which is longer than the specified 1000\n",
      "Created a chunk of size 1973, which is longer than the specified 1000\n",
      "Created a chunk of size 1581, which is longer than the specified 1000\n",
      "Created a chunk of size 1993, which is longer than the specified 1000\n",
      "Created a chunk of size 3878, which is longer than the specified 1000\n",
      "Created a chunk of size 1521, which is longer than the specified 1000\n",
      "Created a chunk of size 1523, which is longer than the specified 1000\n",
      "Created a chunk of size 1467, which is longer than the specified 1000\n",
      "Created a chunk of size 2714, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 1477, which is longer than the specified 1000\n",
      "Created a chunk of size 2863, which is longer than the specified 1000\n",
      "Created a chunk of size 1508, which is longer than the specified 1000\n",
      "Created a chunk of size 1294, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 1355, which is longer than the specified 1000\n",
      "Created a chunk of size 2352, which is longer than the specified 1000\n",
      "Created a chunk of size 1700, which is longer than the specified 1000\n",
      "Created a chunk of size 1460, which is longer than the specified 1000\n",
      "Created a chunk of size 1902, which is longer than the specified 1000\n",
      "Created a chunk of size 2208, which is longer than the specified 1000\n",
      "Created a chunk of size 1482, which is longer than the specified 1000\n",
      "Created a chunk of size 3652, which is longer than the specified 1000\n",
      "Created a chunk of size 1998, which is longer than the specified 1000\n",
      "Created a chunk of size 1927, which is longer than the specified 1000\n",
      "Created a chunk of size 2859, which is longer than the specified 1000\n",
      "Created a chunk of size 1432, which is longer than the specified 1000\n",
      "Created a chunk of size 2550, which is longer than the specified 1000\n",
      "Created a chunk of size 1063, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1730, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1230, which is longer than the specified 1000\n",
      "Created a chunk of size 1328, which is longer than the specified 1000\n",
      "Created a chunk of size 4766, which is longer than the specified 1000\n",
      "Created a chunk of size 1488, which is longer than the specified 1000\n",
      "Created a chunk of size 1253, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n",
      "Created a chunk of size 1078, which is longer than the specified 1000\n",
      "Created a chunk of size 1712, which is longer than the specified 1000\n",
      "Created a chunk of size 1083, which is longer than the specified 1000\n",
      "Created a chunk of size 3322, which is longer than the specified 1000\n",
      "Created a chunk of size 1043, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1132, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "texts = [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedding vectors \n",
    "\n",
    "We put all vectors into the sqlite-vss in a table named ```twenty_thousand_leagues_under_the_sea```.\n",
    "The db_file parameter is the name of the file you want as your sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.from_documents(\n",
    "    documents=docs, \n",
    "    embedding=embeddings_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the Nautilus?\"\n",
    "docs = vector_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cast a last look at the man-of-war, which was putting on steam, and\n",
      "rejoined Ned and Conseil.\n",
      "\n",
      "“We will fly!” I exclaimed.\n",
      "\n",
      "“Good!” said Ned. “What is this vessel?”\n",
      "\n",
      "“I do not know; but, whatever it is, it will be sunk before night. In\n",
      "any case, it is better to perish with it, than be made accomplices in a\n",
      "retaliation the justice of which we cannot judge.”\n",
      "\n",
      "“That is my opinion too,” said Ned Land, coolly. “Let us wait for\n",
      "night.”\n",
      "Thus the _Abraham Lincoln_ wanted for no means of destruction; and,\n",
      "what was better still, she had on board Ned Land, the prince of\n",
      "harpooners.\n",
      "\n",
      "Ned Land was a Canadian, with an uncommon quickness of hand, and who\n",
      "knew no equal in his dangerous occupation. Skill, coolness, audacity,\n",
      "and cunning he possessed in a superior degree, and it must be a cunning\n",
      "whale or a singularly “cute” cachalot to escape the stroke of his\n",
      "harpoon.\n",
      "\n",
      "Ned Land was about forty years of age; he was a tall man (more than six\n",
      "feet high), strongly built, grave and taciturn, occasionally violent,\n",
      "and very passionate when contradicted. His person attracted attention,\n",
      "but above all the boldness of his look, which gave a singular\n",
      "expression to his face.\n",
      "“Good!” said the disappointed harpooner, who saw his dreams of fresh\n",
      "meat fade away. “And you, M. Aronnax, are you going to dress yourself\n",
      "in those clothes?”\n",
      "\n",
      "“There is no alternative, Master Ned.”\n",
      "\n",
      "“As you please, sir,” replied the harpooner, shrugging his shoulders;\n",
      "“but as for me, unless I am forced, I will never get into one.”\n",
      "\n",
      "“No one will force you, Master Ned,” said Captain Nemo.\n",
      "\n",
      "“Is Conseil going to risk it?” asked Ned.\n",
      "\n",
      "“I follow my master wherever he goes,” replied Conseil.\n",
      "“And why this powerful organisation?” demanded Ned.\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is Ned's last name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus the _Abraham Lincoln_ wanted for no means of destruction; and,\n",
      "what was better still, she had on board Ned Land, the prince of\n",
      "harpooners.\n",
      "\n",
      "Ned Land was a Canadian, with an uncommon quickness of hand, and who\n",
      "knew no equal in his dangerous occupation. Skill, coolness, audacity,\n",
      "and cunning he possessed in a superior degree, and it must be a cunning\n",
      "whale or a singularly “cute” cachalot to escape the stroke of his\n",
      "harpoon.\n",
      "\n",
      "Ned Land was about forty years of age; he was a tall man (more than six\n",
      "feet high), strongly built, grave and taciturn, occasionally violent,\n",
      "and very passionate when contradicted. His person attracted attention,\n",
      "but above all the boldness of his look, which gave a singular\n",
      "expression to his face.\n",
      "“And why this powerful organisation?” demanded Ned.\n",
      "I cast a last look at the man-of-war, which was putting on steam, and\n",
      "rejoined Ned and Conseil.\n",
      "\n",
      "“We will fly!” I exclaimed.\n",
      "\n",
      "“Good!” said Ned. “What is this vessel?”\n",
      "\n",
      "“I do not know; but, whatever it is, it will be sunk before night. In\n",
      "any case, it is better to perish with it, than be made accomplices in a\n",
      "retaliation the justice of which we cannot judge.”\n",
      "\n",
      "“That is my opinion too,” said Ned Land, coolly. “Let us wait for\n",
      "night.”\n",
      "“Good!” said the disappointed harpooner, who saw his dreams of fresh\n",
      "meat fade away. “And you, M. Aronnax, are you going to dress yourself\n",
      "in those clothes?”\n",
      "\n",
      "“There is no alternative, Master Ned.”\n",
      "\n",
      "“As you please, sir,” replied the harpooner, shrugging his shoulders;\n",
      "“but as for me, unless I am forced, I will never get into one.”\n",
      "\n",
      "“No one will force you, Master Ned,” said Captain Nemo.\n",
      "\n",
      "“Is Conseil going to risk it?” asked Ned.\n",
      "\n",
      "“I follow my master wherever he goes,” replied Conseil.\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Answer the question based only on the supplied context. If you don't know the answer, say you don't know the answer.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Your answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text does not mention the Nautilus, therefore I cannot answer the question. The text does not describe the Nautilus."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = chain.invoke(\"What is the Nautilus?\")\n",
    "display(Markdown(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
