{
  "nodes": [
    {
      "id": "recursiveCharacterTextSplitter_0",
      "position": {
        "x": 280.12,
        "y": 389.40800000000013
      },
      "type": "customNode",
      "data": {
        "id": "recursiveCharacterTextSplitter_0",
        "label": "Recursive Character Text Splitter",
        "version": 2,
        "name": "recursiveCharacterTextSplitter",
        "type": "RecursiveCharacterTextSplitter",
        "baseClasses": [
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "default": 1000,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number"
          },
          {
            "label": "Custom Separators",
            "name": "separators",
            "type": "string",
            "rows": 4,
            "description": "Array of custom separators to determine when to split the text, will override the default separators",
            "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
            "additionalParams": true,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-separators-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": "",
          "separators": ""
        },
        "outputAnchors": [
          {
            "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "recursiveCharacterTextSplitter",
            "label": "RecursiveCharacterTextSplitter",
            "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
            "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 430,
      "selected": false,
      "positionAbsolute": {
        "x": 280.12,
        "y": 389.40800000000013
      },
      "dragging": false
    },
    {
      "id": "faiss_0",
      "position": {
        "x": 1275.406020721951,
        "y": 1215.6440032
      },
      "type": "customNode",
      "data": {
        "id": "faiss_0",
        "label": "Faiss",
        "version": 1,
        "name": "faiss",
        "type": "Faiss",
        "baseClasses": [
          "Faiss",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity search upon query using Faiss library from Meta",
        "inputParams": [
          {
            "label": "Base Path to load",
            "name": "basePath",
            "description": "Path to load faiss.index file",
            "placeholder": "C:\\Users\\User\\Desktop",
            "type": "string",
            "id": "faiss_0-input-basePath-string"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "faiss_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "faiss_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "faiss_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{plainText_0.data.instance}}"
          ],
          "embeddings": "{{azureOpenAIEmbeddings_0.data.instance}}",
          "basePath": "pdf-rag-embeddings",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Faiss Retriever",
                "description": "",
                "type": "Faiss | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "faiss_0-output-vectorStore-Faiss|SaveableVectorStore|VectorStore",
                "name": "vectorStore",
                "label": "Faiss Vector Store",
                "description": "",
                "type": "Faiss | SaveableVectorStore | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 459,
      "positionAbsolute": {
        "x": 1275.406020721951,
        "y": 1215.6440032
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 1754.4453759999994,
        "y": 673.7768320000001
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 3,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{azureChatOpenAI_0.data.instance}}",
          "vectorStoreRetriever": "{{faiss_0.data.instance}}",
          "memory": "",
          "returnSourceDocuments": false,
          "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 532,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1754.4453759999994,
        "y": 673.7768320000001
      }
    },
    {
      "id": "plainText_0",
      "position": {
        "x": 783.2508218206009,
        "y": 379.387932686151
      },
      "type": "customNode",
      "data": {
        "id": "plainText_0",
        "label": "Plain Text",
        "version": 2,
        "name": "plainText",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from plain text",
        "inputParams": [
          {
            "label": "Text",
            "name": "text",
            "type": "string",
            "rows": 4,
            "placeholder": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua...",
            "id": "plainText_0-input-text-string"
          },
          {
            "label": "Metadata",
            "name": "metadata",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "plainText_0-input-metadata-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "plainText_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "text": "How long we slept I do not know; but our sleep must have lasted long,\nfor it rested us completely from our fatigues. I woke first. My\ncompanions had not moved, and were still stretched in their corner.\n\nHardly roused from my somewhat hard couch, I felt my brain freed, my\nmind clear. I then began an attentive examination of our cell. Nothing\nwas changed inside. The prison was still a prison,—the prisoners,\nprisoners. However, the steward, during our sleep, had cleared the\ntable. I breathed with difficulty. The heavy air seemed to oppress my\nlungs. Although the cell was large, we had evidently consumed a great\npart of the oxygen that it contained. Indeed, each man consumes, in one\nhour, the oxygen contained in more than 176 pints of air, and this air,\ncharged (as then) with a nearly equal quantity of carbonic acid,\nbecomes unbreathable.\n\nIt became necessary to renew the atmosphere of our prison, and no doubt\nthe whole in the submarine boat. That gave rise to a question in my\nmind. How would the commander of this floating dwelling-place proceed?\nWould he obtain air by chemical means, in getting by heat the oxygen\ncontained in chlorate of potash, and in absorbing carbonic acid by\ncaustic potash? Or, a more convenient, economical, and consequently\nmore probable alternative, would he be satisfied to rise and take\nbreath at the surface of the water, like a cetacean, and so renew for\ntwenty-four hours the atmospheric provision?\n\nIn fact, I was already obliged to increase my respirations to eke out\nof this cell the little oxygen it contained, when suddenly I was\nrefreshed by a current of pure air, and perfumed with saline\nemanations. It was an invigorating sea breeze, charged with iodine. I\nopened my mouth wide, and my lungs saturated themselves with fresh\nparticles.\n\nAt the same time I felt the boat rolling. The iron-plated monster had\nevidently just risen to the surface of the ocean to breathe, after the\nfashion of whales. I found out from that the mode of ventilating the\nboat.\n\nWhen I had inhaled this air freely, I sought the conduit-pipe, which\nconveyed to us the beneficial whiff, and I was not long in finding it.\nAbove the door was a ventilator, through which volumes of fresh air\nrenewed the impoverished atmosphere of the cell.\n\nI was making my observations, when Ned and Conseil awoke almost at the\nsame time, under the influence of this reviving air. They rubbed their\neyes, stretched themselves, and were on their feet in an instant.\n\n“Did master sleep well?” asked Conseil, with his usual politeness.\n\n“Very well, my brave boy. And you, Mr. Land?”\n\n“Soundly, Professor. But I don’t know if I am right or not; there seems\nto be a sea breeze!”\n\nA seaman could not be mistaken, and I told the Canadian all that had\npassed during his sleep.\n\n“Good!” said he; “that accounts for those roarings we heard, when the\nsupposed narwhal sighted the _Abraham Lincoln_.”\n\n“Quite so, Master Land; it was taking breath.”\n\n“Only, Mr. Aronnax, I have no idea what o’clock it is, unless it is\ndinner-time.”\n\n“Dinner-time! my good fellow? Say rather breakfast-time, for we\ncertainly have begun another day.”\n\n“So,” said Conseil, “we have slept twenty-four hours?”\n\n“That is my opinion.”\n\n“I will not contradict you,” replied Ned Land. “But dinner or\nbreakfast, the steward will be welcome, whichever he brings.”\n\n“Master Land, we must conform to the rules on board, and I suppose our\nappetites are in advance of the dinner hour.”\n\n“That is just like you, friend Conseil,” said Ned, impatiently. “You\nare never out of temper, always calm; you would return thanks before\ngrace, and die of hunger rather than complain!”\n\nTime was getting on, and we were fearfully hungry; and this time the\nsteward did not appear. It was rather too long to leave us, if they\nreally had good intentions towards us. Ned Land, tormented by the\ncravings of hunger, got still more angry; and, notwithstanding his\npromise, I dreaded an explosion when he found himself with one of the\ncrew.\n\nFor two hours more Ned Land’s temper increased; he cried, he shouted,\nbut in vain. The walls were deaf. There was no sound to be heard in the\nboat: all was still as death. It did not move, for I should have felt\nthe trembling motion of the hull under the influence of the screw.\nPlunged in the depths of the waters, it belonged no longer to\nearth:—this silence was dreadful.\n\nI felt terrified, Conseil was calm, Ned Land roared.\n\nJust then a noise was heard outside. Steps sounded on the metal flags.\nThe locks were turned, the door opened, and the steward appeared.\n\nBefore I could rush forward to stop him, the Canadian had thrown him\ndown, and held him by the throat. The steward was choking under the\ngrip of his powerful hand.\n\nConseil was already trying to unclasp the harpooner’s hand from his\nhalf-suffocated victim, and I was going to fly to the rescue, when\nsuddenly I was nailed to the spot by hearing these words in French—\n\n“Be quiet, Master Land; and you, Professor, will you be so good as to\nlisten to me?”",
          "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
          "metadata": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "plainText_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "plainText_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 487,
      "positionAbsolute": {
        "x": 783.2508218206009,
        "y": 379.387932686151
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "azureChatOpenAI_0",
      "position": {
        "x": 1194.5346269531913,
        "y": 303.4293457832904
      },
      "type": "customNode",
      "data": {
        "id": "azureChatOpenAI_0",
        "label": "Azure ChatOpenAI",
        "version": 3,
        "name": "azureChatOpenAI",
        "type": "AzureChatOpenAI",
        "baseClasses": [
          "AzureChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Azure OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "azureOpenAIApi"
            ],
            "id": "azureChatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "options",
            "options": [
              {
                "label": "gpt-4",
                "name": "gpt-4"
              },
              {
                "label": "gpt-4-32k",
                "name": "gpt-4-32k"
              },
              {
                "label": "gpt-35-turbo",
                "name": "gpt-35-turbo"
              },
              {
                "label": "gpt-35-turbo-16k",
                "name": "gpt-35-turbo-16k"
              },
              {
                "label": "gpt-4-vision-preview",
                "name": "gpt-4-vision-preview"
              }
            ],
            "default": "gpt-35-turbo",
            "optional": true,
            "id": "azureChatOpenAI_0-input-modelName-options"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "azureChatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "azureChatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "azureChatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "azureChatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "azureChatOpenAI_0-input-timeout-number"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
            "default": false,
            "optional": true,
            "id": "azureChatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "azureChatOpenAI_0-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "azureChatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-35-turbo",
          "temperature": 0.9,
          "maxTokens": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "azureChatOpenAI_0-output-azureChatOpenAI-AzureChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "azureChatOpenAI",
            "label": "AzureChatOpenAI",
            "description": "Wrapper around Azure OpenAI large language models that use the Chat endpoint",
            "type": "AzureChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 672,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1194.5346269531913,
        "y": 303.4293457832904
      }
    },
    {
      "id": "azureOpenAIEmbeddings_0",
      "position": {
        "x": 613.1599292851063,
        "y": 1189.7662174513753
      },
      "type": "customNode",
      "data": {
        "id": "azureOpenAIEmbeddings_0",
        "label": "Azure OpenAI Embeddings",
        "version": 1,
        "name": "azureOpenAIEmbeddings",
        "type": "AzureOpenAIEmbeddings",
        "baseClasses": [
          "AzureOpenAIEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "Azure OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "azureOpenAIApi"
            ],
            "id": "azureOpenAIEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "default": "100",
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAIEmbeddings_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAIEmbeddings_0-input-timeout-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "batchSize": "100",
          "timeout": ""
        },
        "outputAnchors": [
          {
            "id": "azureOpenAIEmbeddings_0-output-azureOpenAIEmbeddings-AzureOpenAIEmbeddings|Embeddings",
            "name": "azureOpenAIEmbeddings",
            "label": "AzureOpenAIEmbeddings",
            "description": "Azure OpenAI API to generate embeddings for a given text",
            "type": "AzureOpenAIEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 330,
      "selected": false,
      "positionAbsolute": {
        "x": 613.1599292851063,
        "y": 1189.7662174513753
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "faiss_0",
      "sourceHandle": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "faiss_0-faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "recursiveCharacterTextSplitter_0",
      "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "plainText_0",
      "targetHandle": "plainText_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-plainText_0-plainText_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "plainText_0",
      "sourceHandle": "plainText_0-output-document-Document|json",
      "target": "faiss_0",
      "targetHandle": "faiss_0-input-document-Document",
      "type": "buttonedge",
      "id": "plainText_0-plainText_0-output-document-Document|json-faiss_0-faiss_0-input-document-Document"
    },
    {
      "source": "azureChatOpenAI_0",
      "sourceHandle": "azureChatOpenAI_0-output-azureChatOpenAI-AzureChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "azureChatOpenAI_0-azureChatOpenAI_0-output-azureChatOpenAI-AzureChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    },
    {
      "source": "azureOpenAIEmbeddings_0",
      "sourceHandle": "azureOpenAIEmbeddings_0-output-azureOpenAIEmbeddings-AzureOpenAIEmbeddings|Embeddings",
      "target": "faiss_0",
      "targetHandle": "faiss_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "azureOpenAIEmbeddings_0-azureOpenAIEmbeddings_0-output-azureOpenAIEmbeddings-AzureOpenAIEmbeddings|Embeddings-faiss_0-faiss_0-input-embeddings-Embeddings"
    }
  ]
}